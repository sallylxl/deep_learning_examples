#!/bin/bash

set -x
GPU_NUMS=${GPU_NUMS:-128}
if [ $GPU_NUMS -eq 8 ];then
    WORKER_NUMS=0
    WORLD_SIZE=1
else
    WORKER_NUMS=$((GPU_NUMS / 8 -1))
    WORLD_SIZE=$((GPU_NUMS / 8))
fi

MODEL="gpt3_175b_16k_bf16"
DEEP_LEARNING_EXAMPLES_DIR=${DEEP_LEARNING_EXAMPLES_DIR:-"/data/deep_learning_examples"} 
BASE_RESULTS_DIR=${BASE_RESULTS_DIR:-${DEEP_LEARNING_EXAMPLES_DIR}/results}
GPU_TYPE=${GPU_TYPE:-h100}

DEEP_LEARNING_EXAMPLES_DIR=${DEEP_LEARNING_EXAMPLES_DIR} \
BASE_RESULTS_DIR=${BASE_RESULTS_DIR} \
GPU_TYPE=${GPU_TYPE} \
TP=${TP:-8} \
PP=${PP:-8} \
CP=${CP:-8} \
SEQ_LEN=16384 \
GBS=${GBS:-32} \
MBS=${MBS:-1} \
MAX_STEP=${MAX_STEP:-128} \
JOB_PREFIX=$(echo $MODEL | sed 's/_/-/g') \
MODEL=${MODEL} \
RUN_ID=$(date +"%m%dt%H%M%S") \
ENABLE_CKPT=${ENABLE_CKPT:-0} \
UB_TP_COMM_OVERLAP=${UB_TP_COMM_OVERLAP:-0} \
WORLD_SIZE=$WORLD_SIZE RANK="\$RANK" GPU_NUMS=${GPU_NUMS} WORKER_NUMS=${WORKER_NUMS} \
	envsubst < pytorchjob-nemo.yaml.template |kubectl apply -f -
